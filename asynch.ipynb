{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Async: a style of concurrent programming in which tasks release the CPU during waiting periods, so that other tasks can use it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3 ways of doing multiple things at once in Python: multiprocessing, multithreading, asynchronous programming\n",
    "\n",
    "**Multiprocessing and multithreading**\n",
    "\n",
    "Concurrency is when two or more tasks can start, run, and complete in overlapping time periods. It doesn't necessarily mean they'll ever both be running at the same instant. Eg. multitasking on a single-core machine. Parallelism is when two or more tasks  run at the same time, e.g. on a multicore processor. Concurrency can be characterized as a property of a program or system and parallelism as the run-time behaviour of executing multiple tasks at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/concurrency_parallelism.png)\n",
    "If we ran this program on a computer with a single CPU core, the OS would be switching between the two threads, allowing one thread to run at a time. If we ran this program on a computer with a multi-core CPU then we would be able to run the two threads in parallel - side by side at the exact same time\n",
    "\n",
    "A thread is a sequence of instructions within a process. It can be thought of as a lightweight process. Threads share the same memory space. A process is an instance of a program running in a computer which can contain one or more threads. A process has its independant memory space. \n",
    "    \n",
    "The threading module is used for working with threads in Python. The CPython implementation has a Global Interpreter Lock (GIL) which allows only one thread to be active in the interpreter at once. The mechanism used by the CPython interpreter to assure that only one thread executes Python bytecode at a time. This simplifies the CPython implementation by making the object model (including critical built-in types such as dict) implicitly safe against concurrent access. Locking the entire interpreter makes it easier for the interpreter to be multi-threaded, at the expense of much of the parallelism afforded by multi-processor machines. This means that threads cannot be used for parallel execution of Python code. While parallel CPU computation is not possible, parallel IO operations are possible using threads. This is because performing IO operations releases the GIL. What are threads used for in Python? \n",
    "\n",
    "    In GUI applications to keep the UI thread responsive\n",
    "\n",
    "    IO tasks (network IO or filesystem IO)\n",
    "\n",
    "Using threads for these tasks improves performance, since in network IO for example, most of the time is spent waiting for a response from the URL. Threads should not be used for CPU bound tasks as this will actually result in worse performance compared to using a single thread.\n",
    "\n",
    "For parallel execution of tasks use multiprocessing, a package that supports spawning processes using an API similar to the threading module. It side-steps the GIL by using subprocesses instead of threads. The Pool object which offers a convenient means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (data parallelism).\n",
    "\n",
    "**Using coroutines to run functions concurrently**\n",
    "\n",
    "While threads are useful for blocking I/O, they should be avoided for parallel procesessing. Three problems with threads: special tools are needed e.g. to prevent data races, which increases code complexity and difficultly with its maintenance, and executing threads requires uses a lot of memory and are costly to start. \n",
    "\n",
    "Python work around these rpoblem with coroutines. These allow you to have many seemingly simultaneous functions running in your programs. They are are extension of generators and the cost of starting them is just a function call and require only a small amount of memory until they are exhausted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, how does Python do multiple things at once?\n",
    "\n",
    "1 - Multiple processes\n",
    "\n",
    "The most obvious way is to use multiple processes. From the terminal you can start your script two, three, four…ten times and then all the scripts are going to run independently or at the same time. The operating system that's underneath will take care of sharing your CPU resources among all those instances. Using CPython that's actually the only way you can get to use more than one CPU at the same time.\n",
    "\n",
    "2 - Multiple threads\n",
    "\n",
    "The next way to run multiple things at once is to use threads.\n",
    "\n",
    "A thread is a line of execution, pretty much like a process, but you can have multiple threads in the context of one process and they all share access to common resources. But because of this it's difficult to write a threading code. And again, the operating system is doing all the heavy lifting on sharing the CPU, but the global interpreter lock (GIL) allows only one thread to run Python code at a given time even when you have multiple threads running code. So, In CPython, the GIL prevents multi core concurrency. Basically, you’re running in a single core even though you may have two or four or more.\n",
    "\n",
    "3 - Asynchronous Programming\n",
    "\n",
    "The third way is an asynchronous programming, where the OS is not participating. As far as OS is concerned you're going to have one process and there's going to be a single thread within that process, but you'll be able to do multiple things at once. So, what's the trick? \n",
    "\n",
    "Much of the code we write, especially in heavy IO applications like websites, depends on external resources. This could be anything from a remote database call to POSTing to a REST service. As soon as you ask for any of these resources, your code is waiting around with nothing to do. With asynchronous programming, you allow your code to handle other tasks while waiting for these other resources to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_gen():\n",
    "    for i in range(10):\n",
    "        if i % 2 == 0:\n",
    "            yield i\n",
    "        \n",
    "g = my_gen()\n",
    "g.send(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coroutines: a background\n",
    "-------------------------\n",
    "\n",
    "Coroutines have similarities to generators. When you call a generator function, a generator object is returned. The function is not run, it only executes on `next()`. Yield produces a value but the function is suspended and resumes on the next call to `next()` until StopIteration is reached.\n",
    "\n",
    "Following PEP-342, you can use `yield` in expressions, such as the RHS of assignments. If you use `yield` more generally, you get a coroutine. These do more than generate values, they can consume values sent to them (you can only send None to a generator, effectively the same as calling `next()` on it). Values sent to them are returned by (yield):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for Python\n"
     ]
    }
   ],
   "source": [
    "def grep(pattern):\n",
    "    print (\"Looking for {}\".format(pattern))\n",
    "    while True:        \n",
    "        line = (yield)       \n",
    "        if pattern in line:            \n",
    "            print(line)\n",
    "            \n",
    "g = grep('Python')\n",
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution is similar as for generators. 'Priming' the coroutine by calling `next()` or `.send(None)` advances the coroutine to the first `yield` and execution is suspended until it is sent a value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python, you are so cool\n"
     ]
    }
   ],
   "source": [
    "g.send('no snakes here')\n",
    "g.send('Python, you are so cool')\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The need to call next()`can be solved using a decorator :\n",
    "\n",
    "def coroutine(func):    \n",
    "    def start(*args,**kwargs):        \n",
    "        cr = func(*args,**kwargs)        \n",
    "        next(cr)        \n",
    "        return cr    \n",
    "    return start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing Pipelines**\n",
    "\n",
    "Coroutines can be used to set up pipes. You just chain coroutines together and push data through the pipe with `send()` operations\n",
    "\n",
    "![](images/proc_pipeline.png)\n",
    "\n",
    "The source (typically not a coroutine) drives the pipeline. You can have branching and arbitrarily complex routing of data: \n",
    "\n",
    "![](images/pipeline_branch.png)\n",
    "\n",
    "Coroutines provide more powerful data routing possibilities than simple iterators. If you built a collection of simple data processing components, you can glue them together into complex arrangements of pipes, branches, merging, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object speak_async at 0x0000019E7B8DA780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def speak_async():  \n",
    "    print('OMG asynchronicity!')\n",
    "\n",
    "# cannot run with something driving it\n",
    "speak_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def speak_async():  \n",
    "    print('OMG asynchronicity!')\n",
    "    \n",
    "async def run_this()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Event loop is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-2e78819e680c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeak_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paul\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mits\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paul\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36m_check_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Event loop is closed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Event loop is closed"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()  \n",
    "loop.run_until_complete(speak_async())  \n",
    "loop.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
